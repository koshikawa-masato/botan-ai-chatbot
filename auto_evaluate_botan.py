#!/usr/bin/env python3
"""
ç‰¡ä¸¹ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ€§ AIè‡ªå‹•è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Claude CodeãŒè‡ªå‹•ã§è©•ä¾¡ã‚’10å›ç¹°ã‚Šè¿”ã™
"""

import requests
import json
from datetime import datetime
import time

def ask_botan(prompt, model="elyza:botan_v2"):
    """ç‰¡ä¸¹ã«è³ªå•"""
    url = "http://localhost:11434/api/generate"

    payload = {
        "model": model,
        "prompt": prompt,
        "stream": False
    }

    try:
        response = requests.post(url, json=payload, timeout=30)
        response.raise_for_status()
        result = response.json()
        return result['response']
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: {e}"

def evaluate_response(prompt, response, category):
    """
    AIã«ã‚ˆã‚‹è‡ªå‹•è©•ä¾¡ï¼ˆ1-5ç‚¹ï¼‰- äººé–“è©•ä¾¡ã«åˆã‚ã›ã¦å³ã—ã‚ã«èª¿æ•´

    ç‰¡ä¸¹ã‚‰ã—ã•ã®è©•ä¾¡åŸºæº–:
    - ã€é‡è¦ã€‘èªå½™åŠ›ãŒå°‘ãªãè¦‹ãˆã¦ã€ç†è§£ã¯ã—ã¦ã„ã‚‹
    - ã€é‡è¦ã€‘é•·ã£ãŸã‚‰ã—ãè¨€ã‚ãªã„ï¼ˆç°¡æ½”ã•ï¼‰
    - çŸ¥è­˜ã‚’ã²ã‘ã‚‰ã‹ã•ãªã„
    - ã”ã¾ã‹ã™ã€ã¨ã¼ã‘ã‚‹
    - æ„Ÿæƒ…è±Šã‹ï¼ˆã€Œãƒã‚¸ã§ã€ã€Œãƒ¤ãƒã„ã€ã€Œã€œã˜ã‚ƒã‚“ã€ï¼‰
    - AIã£ã½ããªã„

    å°†æ¥çš„ãªæ‹¡å¼µ:
    - æ€§æ ¼ä»˜ã‘ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…æ™‚ã¯ã€Œè‡ªåˆ†èªã‚Šã—ãŸã„ç‰¡ä¸¹ã€ã®æš´èµ°OK
    - PONã‚·ã‚¹ãƒ†ãƒ ï¼ˆã‚„ã‚‰ã‹ã—ï¼‰å®Ÿè£…æ™‚ã¯ç©æ¥µçš„ã«å–‹ã‚‹ã®ã‚‚OK
    - ç¾åœ¨ã¯åŸºæœ¬çš„ã«ç°¡æ½”ã•ã‚’é‡è¦–
    """

    score = 2.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä¸‹ã’ã‚‹ï¼ˆä¸­å¤®å€¤ï¼‰
    reasons = []

    response_lower = response.lower()
    response_length = len(response)

    # ãƒã‚¸ãƒ†ã‚£ãƒ–è¦ç´ ï¼ˆåŠ ç‚¹ï¼‰
    positive_patterns = {
        "ã‚®ãƒ£ãƒ«èªä½¿ç”¨": ["ã˜ã‚ƒã‚“", "ã‚ˆã­", "ã ã‚ˆ", "ã£ã¦"],
        "æ„Ÿæƒ…è¡¨ç¾": ["ãƒã‚¸ã§", "ãƒ¤ãƒã„", "ã‚ã£ã¡ã‚ƒ", "ãˆã€œ", "ã‚ã€œ"],
        "ã”ã¾ã‹ã—": ["ã‚ã‹ã‚“ãªã„", "å¿˜ã‚Œ", "çŸ¥ã‚‰ãª", "è‹¦æ‰‹"],
        "ä¸€äººç§°": ["ã¼ãŸã‚“"],
    }

    # ãƒã‚¬ãƒ†ã‚£ãƒ–è¦ç´ ï¼ˆæ¸›ç‚¹ã‚’å¼·åŒ–ï¼‰- èª¬æ˜çš„ãªè¡¨ç¾ã‚’å³ã—ããƒã‚§ãƒƒã‚¯
    negative_patterns = {
        "AIã£ã½ã„": ["ã§ã™ã€‚", "ã¾ã™ã€‚", "ã«ã¤ã„ã¦", "ã‚‰ã‚Œã¾ã™", "ã”ã–ã„ã¾ã™", "ãªã‚Šã¾ã™"],
        "è©³ã—ã™ã": ["ãƒ¡ãƒ¼ãƒˆãƒ«", "ã‚»ãƒ³ãƒ", "ã‚­ãƒ­", "è©³ã—ã", "å…·ä½“çš„", "æ­£ç¢º"],
        "å …ã„è¡¨ç¾": ["èª¬æ˜", "è§£èª¬", "æƒ…å ±", "ãƒ‡ãƒ¼ã‚¿", "ä¸€èˆ¬çš„", "å ´åˆ", "ä¾‹ãˆã°"],
        "æ•™ç§‘æ›¸çš„": ["ã¨ã¯", "ã¨ã„ã†", "ã¨ã„ã£ãŸ", "ãªã©ã®", "ã¤ã¾ã‚Š", "è¦ã™ã‚‹ã«"],
        "é•·æ–‡èª¬æ˜": ["ãã‚Œã§", "ãªã®ã§", "ã ã‹ã‚‰", "ã§ã™ãŒã€", "ã¾ã™ãŒã€"],
    }

    positive_score = 0
    negative_score = 0

    # ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒã‚§ãƒƒã‚¯ï¼ˆã‚«ã‚¦ãƒ³ãƒˆæ–¹å¼ã‹ã‚‰åŠ ç‚¹æ–¹å¼ã¸ï¼‰
    for pattern_type, patterns in positive_patterns.items():
        matched = False
        for pattern in patterns:
            if pattern in response:
                matched = True
                reasons.append(f"âœ… {pattern_type}: '{pattern}'ã‚’ä½¿ç”¨")
                break
        if matched:
            positive_score += 0.5  # åŠ ç‚¹ã‚’æ§ãˆã‚ã«

    # ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒã‚§ãƒƒã‚¯ï¼ˆæ¸›ç‚¹ã‚’å¼·åŒ–ï¼‰
    for pattern_type, patterns in negative_patterns.items():
        matched = False
        for pattern in patterns:
            if pattern in response:
                matched = True
                reasons.append(f"âŒ {pattern_type}: '{pattern}'ã‚’ä½¿ç”¨")
                break
        if matched:
            negative_score += 1.0  # æ¸›ç‚¹ã‚’å¤§ãã

    # ===== å…±é€šè©•ä¾¡1: ç°¡æ½”ã•ï¼ˆé•·ã£ãŸã‚‰ã—ãè¨€ã‚ãªã„ï¼‰ =====
    if response_length <= 50:
        # ç†æƒ³çš„ãªé•·ã•ï¼ˆ30-50æ–‡å­—ï¼‰
        if response_length >= 30:
            positive_score += 0.5
            reasons.append("âœ… ç°¡æ½”ã§ãƒ†ãƒ³ãƒãŒè‰¯ã„ï¼ˆ30-50æ–‡å­—ï¼‰")
        # çŸ­ã‚ï¼ˆ15-30æ–‡å­—ï¼‰ã‚‚OK
        elif response_length >= 15:
            reasons.append("âœ“ çŸ­ã‚ã®å¿œç­”")
    elif response_length <= 70:
        # ã‚„ã‚„é•·ã„ï¼ˆ50-70æ–‡å­—ï¼‰
        negative_score += 0.3
        reasons.append("âš ï¸ ã‚„ã‚„é•·ã„ï¼ˆ50-70æ–‡å­—ï¼‰")
    elif response_length <= 100:
        # é•·ã„ï¼ˆ70-100æ–‡å­—ï¼‰
        negative_score += 1.0
        reasons.append("âŒ é•·ã™ãã‚‹ï¼ˆ70-100æ–‡å­—ï¼‰")
    else:
        # éå¸¸ã«é•·ã„ï¼ˆ100æ–‡å­—è¶…ï¼‰
        negative_score += 1.5
        reasons.append("âŒâŒ é•·ã£ãŸã‚‰ã—ã„ï¼ˆ100æ–‡å­—è¶…ï¼‰")

    # ===== å…±é€šè©•ä¾¡2: èªå½™åŠ›ãŒå°‘ãªãè¦‹ãˆã¦ç†è§£ã—ã¦ã„ã‚‹ =====
    # é›£ã—ã„ã‚«ã‚¿ã‚«ãƒŠèªï¼ˆAIãƒ»å°‚é–€ç”¨èªã£ã½ã„ï¼‰
    difficult_katakana = ["ã‚·ã‚¹ãƒ†ãƒ ", "ãƒ—ãƒ­ã‚°ãƒ©ãƒ ", "ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ", "ãƒ‡ãƒ¼ã‚¿", "ãƒ—ãƒ­ã‚»ã‚¹", "ãƒ¡ã‚«ãƒ‹ã‚ºãƒ "]
    has_difficult_katakana = any(word in response for word in difficult_katakana)
    if has_difficult_katakana:
        negative_score += 1.0
        reasons.append("âŒ é›£ã—ã„ã‚«ã‚¿ã‚«ãƒŠèªã‚’ä½¿ç”¨ï¼ˆèªå½™åŠ›ãŒé«˜ãè¦‹ãˆã‚‹ï¼‰")

    # è¤‡é›‘ãªæ¼¢å­—ãƒ»å°‚é–€ç”¨èª
    difficult_words = ["å®Ÿè£…", "æ©Ÿèƒ½", "è¨­å®š", "æ§‹é€ ", "å‡¦ç†", "æœ€é©", "åŠ¹ç‡"]
    has_difficult_words = any(word in response for word in difficult_words)
    if has_difficult_words:
        negative_score += 0.8
        reasons.append("âŒ é›£ã—ã„è¨€è‘‰ã‚’ä½¿ç”¨ï¼ˆAIã£ã½ã„ï¼‰")

    # ã‚·ãƒ³ãƒ—ãƒ«ãªè¨€è‘‰ã§çš„ã‚’å°„ãŸå¿œç­”ï¼ˆã²ã‚‰ãŒãªå¤šã‚ï¼‰
    hiragana_ratio = sum(1 for c in response if '\u3040' <= c <= '\u309F') / len(response) if response else 0
    if hiragana_ratio > 0.6:  # ã²ã‚‰ãŒãª60%ä»¥ä¸Š
        positive_score += 0.5
        reasons.append("âœ… ã²ã‚‰ãŒãªå¤šã‚ï¼ˆèªå½™åŠ›å°‘ãªãè¦‹ãˆã‚‹ï¼‰")

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ç‰¹åˆ¥è©•ä¾¡
    if category == "çŸ¥è­˜ã‚’ã²ã‘ã‚‰ã‹ã•ãªã„":
        # æ­£ç¢ºãªæ•°å­—ã‚„è©³ã—ã„èª¬æ˜ãŒã‚ã£ãŸã‚‰å¤§ããæ¸›ç‚¹
        if any(char.isdigit() for char in response):
            # æ•°å­—ãŒã‚ã£ã¦ã‚‚æ›–æ˜§ãªã‚‰OK
            if "ï¼Ÿ" in response or "ã‹ã‚‚" in response or "ã€œ" in response or "ãã‚‰ã„" in response:
                positive_score += 0.5
                reasons.append("âœ… æ•°å­—ã‚’ä½¿ã£ã¦ã„ã‚‹ãŒæ›–æ˜§")
            else:
                negative_score += 1.5  # å¤§ããæ¸›ç‚¹
                reasons.append("âŒ æ­£ç¢ºãªæ•°å­—ã‚’ç­”ãˆã¦ã„ã‚‹")

        # ã”ã¾ã‹ã—ãƒ¯ãƒ¼ãƒ‰ã®è©•ä¾¡ï¼ˆé•·ã•ã«ã‚ˆã£ã¦åŠ ç‚¹ã‚’èª¿æ•´ï¼‰
        has_gomakashi = any(word in response for word in ["ã‚ã‹ã‚“ãªã„", "çŸ¥ã‚‰ãªã„", "å¿˜ã‚Œ", "è‹¦æ‰‹"])
        if has_gomakashi:
            # çŸ­ãã‚µãƒƒã¨ã”ã¾ã‹ã™ = ç‰¡ä¸¹ã‚‰ã—ã„
            if len(response) < 30:
                positive_score += 2.0  # çŸ­ãã”ã¾ã‹ã™ = å®Œç’§
                reasons.append("âœ…âœ… çŸ­ãã‚µãƒƒã¨ã”ã¾ã‹ã™ï¼ˆå®Œç’§ï¼‰")
            elif len(response) < 50:
                positive_score += 1.0  # ã¾ã‚ã¾ã‚
                reasons.append("âœ… ã”ã¾ã‹ã—ã¦ã„ã‚‹ãŒå°‘ã—é•·ã„")
            else:
                # é•·ã€…ã¨ã”ã¾ã‹ã™ = AIã£ã½ã„
                negative_score += 0.5
                reasons.append("âŒ é•·ã€…ã¨ã”ã¾ã‹ã—ã¦ã„ã‚‹ï¼ˆAIã£ã½ã„ï¼‰")
        else:
            # ã”ã¾ã‹ã•ãšã«ç­”ãˆã¦ã„ãŸã‚‰æ¸›ç‚¹
            if len(response) > 30:  # ã‚ã‚‹ç¨‹åº¦ã®é•·ã•ã§ç­”ãˆã¦ã„ã‚‹
                negative_score += 1.0  # æ¸›ç‚¹ã‚’å¼·åŒ–
                reasons.append("âŒ çŸ¥è­˜ã‚’èª¬æ˜ã—ã¦ã„ã‚‹")

    elif category == "æ„Ÿæƒ…è¡¨ç¾":
        # æ„Ÿæƒ…è¡¨ç¾ã‚«ãƒ†ã‚´ãƒªã¯ç›¸æ‰‹ã®æ„Ÿæƒ…ã«é©åˆ‡ã«å¿œãˆã¦ã„ã‚‹ã‹ãŒé‡è¦
        # å…±æ„Ÿã‚„æ„Ÿæƒ…çš„ãªå¿œç­”ãŒå¿…è¦
        emotional_words = ["å¬‰ã—ã„", "æ¥½ã—ã„", "ã‚ã‹ã‚‹", "ã„ã„ã­", "ã‹ã‚ã„ã„", "ç–²ã‚ŒãŸ", "å¤§å¤‰", "æ°—ã«ãªã‚‹", "èˆˆå‘³"]
        has_emotion = any(word in response for word in emotional_words)

        # ç–‘å•å½¢ã§ã®åå¿œã‚‚æ„Ÿæƒ…çš„ãªå¿œç­”ã¨ã¿ãªã™
        question_reaction = any(word in response for word in ["ä½•", "æ•™ãˆã¦", "ï¼Ÿ"])

        if has_emotion or question_reaction:
            positive_score += 0.5
            reasons.append("âœ… æ„Ÿæƒ…çš„ãªå¿œç­”ã‚ã‚Š")
        else:
            negative_score += 0.5  # æ¸›ç‚¹ã‚’ç·©å’Œï¼ˆ1.0â†’0.5ï¼‰
            reasons.append("âŒ æ„Ÿæƒ…çš„ãªå¿œç­”ãŒä¸è¶³")

        # è‡ªåˆ†ã®æ„Ÿæƒ…ã‚’è¡¨ç¾ã—ã¦ã„ã‚‹ã‹
        self_emotion = any(word in response for word in ["ã¼ãŸã‚“ã‚‚", "ã‚ãŸã—ã‚‚", "ç§ã‚‚", "ã¼ãŸã‚“ã€", "ã¼ãŸã‚“ãŒ"])
        if self_emotion:
            positive_score += 0.5
            reasons.append("âœ… è‡ªåˆ†ã®æ„Ÿæƒ…ã‚‚è¡¨ç¾")

    elif category == "ã‚®ãƒ£ãƒ«èª":
        # ã‚®ãƒ£ãƒ«èªã‚«ãƒ†ã‚´ãƒªã¯èªå°¾ã‚„è¡¨ç¾ãŒé‡è¦
        gal_endings = ["ã˜ã‚ƒã‚“", "ã‚ˆã­", "ã ã‚ˆ", "ã‹ã‚‚", "ã£ã¦"]
        ending_count = sum(1 for ending in gal_endings if ending in response)

        if ending_count == 0:
            negative_score += 0.5
            reasons.append("âŒ ã‚®ãƒ£ãƒ«èªã®èªå°¾ãŒä¸è¶³")
        elif ending_count >= 2:
            positive_score += 0.5
            reasons.append("âœ… ã‚®ãƒ£ãƒ«èªã®èªå°¾ãŒè±Šå¯Œ")
        else:
            # 1ã¤ã§ã‚‚èªå°¾ãŒã‚ã‚Œã°OK
            positive_score += 0.3
            reasons.append("âœ… ã‚®ãƒ£ãƒ«èªã®èªå°¾ã‚ã‚Š")

    # é•·ã•ãƒã‚§ãƒƒã‚¯ï¼ˆçŸ­ã„æ–¹ãŒè‰¯ã„ï¼‰- ã‚µãƒƒã¨çµ‚ã‚ã‚‰ã›ã‚‹
    if len(response) < 30:
        positive_score += 1.0  # ã‚µãƒƒã¨çµ‚ã‚ã‚‰ã›ã‚‹ = ç´ æ™´ã‚‰ã—ã„
        reasons.append("âœ…âœ… ã‚µãƒƒã¨çŸ­ãå¿œç­”ï¼ˆç‰¡ä¸¹ã‚‰ã—ã„ï¼‰")
    elif len(response) < 50:
        positive_score += 0.5
        reasons.append("âœ… ç°¡æ½”ãªå¿œç­”")
    elif len(response) > 150:
        negative_score += 1.5  # æ¸›ç‚¹ã‚’ã•ã‚‰ã«å¤§ãã
        reasons.append("âŒâŒ é•·ã™ãã‚‹å¿œç­”ï¼ˆèª¬æ˜çš„ï¼‰")
    elif len(response) > 100:
        negative_score += 1.0  # æ¸›ç‚¹ã‚’å¼·åŒ–
        reasons.append("âŒ ã‚„ã‚„é•·ã„å¿œç­”")
    elif len(response) > 70:
        negative_score += 0.3
        reasons.append("âŒ å°‘ã—é•·ã„")

    # åå‰èªè­˜ã®è©•ä¾¡ï¼ˆè³ªå•ã«ã€Œãƒœã‚¿ãƒ³ã€ã€Œç‰¡ä¸¹ã€ã€Œã¼ãŸã‚“ã€ãŒå«ã¾ã‚Œã‚‹å ´åˆï¼‰
    name_keywords = ["ãƒœã‚¿ãƒ³", "ç‰¡ä¸¹", "ã¼ãŸã‚“"]
    if any(name in prompt for name in name_keywords):
        # è‡ªåˆ†ã®åå‰ã ã¨èªè­˜ã—ã¦åå¿œã—ã¦ã„ã‚‹ã‹
        name_recognition = any(word in response for word in ["ã¼ãŸã‚“ã®ã“ã¨", "è‡ªåˆ†ã®ã“ã¨", "ç§ã®ã“ã¨"])
        # ç¢ºèªã‚’å…¥ã‚Œã¦ã„ã‚‹ã‹
        name_confirmation = any(word in response for word in ["ã¼ãŸã‚“ã®ã“ã¨ï¼Ÿ", "ç§ã®ã“ã¨ï¼Ÿ", "è‡ªåˆ†ã®ã“ã¨ï¼Ÿ"])

        if name_recognition or name_confirmation:
            positive_score += 1.5
            reasons.append("âœ…âœ… åå‰ã‚’èªè­˜ã—ã¦åå¿œï¼ˆé‡è¦ï¼‰")
        else:
            # åå‰ã‚’ç„¡è¦–ã—ã¦åˆ¥ã®è§£é‡ˆã‚’ã—ã¦ã„ã‚‹å ´åˆã¯æ¸›ç‚¹
            negative_score += 1.0
            reasons.append("âŒ åå‰ã‚’èªè­˜ã›ãšåˆ¥ã®è§£é‡ˆ")

    # æœ€çµ‚ã‚¹ã‚³ã‚¢è¨ˆç®—
    score = score + positive_score - negative_score
    score = max(1, min(5, score))  # 1-5ã®ç¯„å›²ã«åã‚ã‚‹
    score = round(score)  # æ•´æ•°ã«ä¸¸ã‚ã‚‹

    return score, reasons

def run_auto_evaluation(num_iterations=10):
    """AIè‡ªå‹•è©•ä¾¡ã‚’è¤‡æ•°å›å®Ÿè¡Œ"""

    test_cases = [
        {
            "category": "çŸ¥è­˜ã‚’ã²ã‘ã‚‰ã‹ã•ãªã„",
            "importance": "æœ€é‡è¦",
            "tests": [
                "æ±äº¬ã‚¿ãƒ¯ãƒ¼ã£ã¦ä½•ãƒ¡ãƒ¼ãƒˆãƒ«ï¼Ÿ",
                "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã£ã¦ä½•ï¼Ÿ",
                "AIã«ã¤ã„ã¦æ•™ãˆã¦",
                "å¯Œå£«å±±ã®é«˜ã•ã¯ï¼Ÿ",
            ]
        },
        {
            "category": "æ„Ÿæƒ…è¡¨ç¾",
            "importance": "é‡è¦",
            "tests": [
                "ä»Šæ—¥ã‚ã£ã¡ã‚ƒå¬‰ã—ã„ã“ã¨ãŒã‚ã£ãŸï¼",
                "ãƒœã‚¿ãƒ³ã£ã¦å¯æ„›ã„ã­",
                "ç–²ã‚Œã¡ã‚ƒã£ãŸ",
            ]
        },
        {
            "category": "ã‚®ãƒ£ãƒ«èª",
            "importance": "é‡è¦",
            "tests": [
                "ãŠã¯ã‚ˆã†",
                "æœ€è¿‘ã©ã†ï¼Ÿ",
                "æ˜æ—¥ä½•ã™ã‚‹ï¼Ÿ",
            ]
        }
    ]

    all_results = {
        "evaluator": "AI (Claude Code)",
        "timestamp": datetime.now().isoformat(),
        "model": "elyza:botan_v2",
        "num_iterations": num_iterations,
        "iterations": []
    }

    print("="*70)
    print("ğŸ¤– AIè‡ªå‹•è©•ä¾¡é–‹å§‹")
    print(f"ç¹°ã‚Šè¿”ã—å›æ•°: {num_iterations}å›")
    print("="*70)

    for iteration in range(1, num_iterations + 1):
        print(f"\n{'='*70}")
        print(f"ğŸ”„ ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ {iteration}/{num_iterations}")
        print('='*70)

        iteration_results = {
            "iteration": iteration,
            "tests": [],
            "timestamp": datetime.now().isoformat()
        }

        total_score = 0
        total_count = 0

        for category_data in test_cases:
            category = category_data["category"]
            tests = category_data["tests"]

            print(f"\nã€{category}ã€‘")

            for prompt in tests:
                print(f"  è³ªå•: {prompt}")

                # ç‰¡ä¸¹ã«è³ªå•
                response = ask_botan(prompt)
                print(f"  å¿œç­”: {response[:80]}{'...' if len(response) > 80 else ''}")

                # AIè©•ä¾¡
                score, reasons = evaluate_response(prompt, response, category)
                print(f"  è©•ä¾¡: {score}/5")

                for reason in reasons:
                    print(f"    {reason}")

                total_score += score
                total_count += 1

                # çµæœè¨˜éŒ²
                iteration_results["tests"].append({
                    "category": category,
                    "prompt": prompt,
                    "response": response,
                    "score": score,
                    "reasons": reasons
                })

                # APIè² è·è»½æ¸›ã®ãŸã‚å°‘ã—å¾…æ©Ÿ
                time.sleep(0.5)

        # ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å¹³å‡ã‚¹ã‚³ã‚¢
        avg_score = total_score / total_count if total_count > 0 else 0
        iteration_results["average_score"] = avg_score

        print(f"\n  ğŸ“Š ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³{iteration}å¹³å‡: {avg_score:.2f}/5.0")

        all_results["iterations"].append(iteration_results)

    # å…¨ä½“ã®çµ±è¨ˆ
    all_scores = [it["average_score"] for it in all_results["iterations"]]
    all_results["overall_stats"] = {
        "min_score": min(all_scores),
        "max_score": max(all_scores),
        "average_score": sum(all_scores) / len(all_scores),
        "total_tests": num_iterations * total_count
    }

    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    filename = f"ai_evaluation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)

    print("\n" + "="*70)
    print("âœ… AIè‡ªå‹•è©•ä¾¡å®Œäº†")
    print("="*70)
    print(f"\nğŸ“Š å…¨ä½“çµ±è¨ˆ:")
    print(f"  æœ€å°ã‚¹ã‚³ã‚¢: {all_results['overall_stats']['min_score']:.2f}/5.0")
    print(f"  æœ€å¤§ã‚¹ã‚³ã‚¢: {all_results['overall_stats']['max_score']:.2f}/5.0")
    print(f"  å¹³å‡ã‚¹ã‚³ã‚¢: {all_results['overall_stats']['average_score']:.2f}/5.0")
    print(f"  ç·ãƒ†ã‚¹ãƒˆæ•°: {all_results['overall_stats']['total_tests']}")
    print(f"\nğŸ’¾ çµæœä¿å­˜: {filename}")

    return filename

if __name__ == "__main__":
    import sys

    num_iterations = 10
    if len(sys.argv) > 1:
        try:
            num_iterations = int(sys.argv[1])
        except:
            pass

    run_auto_evaluation(num_iterations)
